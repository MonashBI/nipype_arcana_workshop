{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customising Banana for Your Analysis\n",
    "\n",
    "Now you understand how to write Arcana Analysis classes and have an idea of what is already implemented in Banana you can customise the analysis implemented in it to your needs.\n",
    "\n",
    "**Note:** Before doing any customisations, have a good look through the parameters of the class to see whether there is already a switch to do what you want.\n",
    "\n",
    "There are a couple of ways you might want to extend an existing class:\n",
    "\n",
    "* Adding/overwriting a new parameter or parameter option\n",
    "* Add new derivatives and pipeline constructors\n",
    "* Overwrite/modify an existing pipeline constructor\n",
    "\n",
    "For this notebook we will use the `BasicBrainAnalysis` class again instead of a \"real\" class from Banana as the analysis in those classes typically takes too long for the time we have available for this workshop. However, the concepts are the same.\n",
    "\n",
    "## Adding/Overwriting Parameters\n",
    "\n",
    "Adding a new parameter to a class is pretty straightforward, simply extend the class and put your new parameter in `add_param_specs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import config\n",
    "config.enable_debug_mode()  # This is necessary due to a bug in one of the interfaces\n",
    "from arcana import Analysis, AnalysisMetaClass, ParamSpec, SwitchSpec\n",
    "from example.analysis import BasicBrainAnalysis\n",
    "\n",
    "\n",
    "class MyExtendendedBasicBrainAnalysis(BasicBrainAnalysis, metaclass=AnalysisMetaClass):\n",
    "    \n",
    "    add_param_specs = [\n",
    "        ParamSpec('bet_frac', 0.1, desc=\"The fractional intensity threshold for BET\")\n",
    "    ]\n",
    "    \n",
    "print(MyExtendendedBasicBrainAnalysis.static_menu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively if you just want to change the default value for an existing parameter you can override it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcana import Analysis, AnalysisMetaClass, ParamSpec, SwitchSpec\n",
    "from example.analysis import BasicBrainAnalysis\n",
    "\n",
    "\n",
    "class MyExtendedBasicBrainAnalysis(BasicBrainAnalysis, metaclass=AnalysisMetaClass):\n",
    "    \n",
    "    add_param_specs = [\n",
    "        ParamSpec('smoothing_fwhm', 2)\n",
    "    ]\n",
    "    \n",
    "print(MyExtendedBasicBrainAnalysis.static_menu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we have lost the description of the parameter because we didn't provide it in the overwritten version. Instead of having to type the same thing again we can generate a new version of the original `ParamSpec` with a new default value by accessing the original from BasicBrainAnalysis and using the `with_new_default` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyExtendedBasicBrainAnalysis(BasicBrainAnalysis, metaclass=AnalysisMetaClass):\n",
    "    \n",
    "    add_param_specs = [\n",
    "        BasicBrainAnalysis.param_spec('smoothing_fwhm').with_new_default(2.0)\n",
    "    ]\n",
    "    \n",
    "print(MyExtendedBasicBrainAnalysis.static_menu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding New Data-Specs\n",
    "\n",
    "Adding new data-specs is the same as adding new parameters just append them to the `add_data_specs` list of your extended class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcana import OutputFilesetSpec\n",
    "from banana.file_format import nifti_gz_format\n",
    "\n",
    "\n",
    "class MyExtendedBasicBrainAnalysis(BasicBrainAnalysis, metaclass=AnalysisMetaClass):\n",
    "    \n",
    "    add_data_specs = [\n",
    "        OutputFilesetSpec('skull_mask', nifti_gz_format,\n",
    "                          'brain_extraction_pipeline',\n",
    "                          desc=\"Skull mask extracted from magnitude image\"),\n",
    "    ]\n",
    "    \n",
    "print(MyExtendedBasicBrainAnalysis.static_menu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying and Overwriting Pipeline Constructor Methods\n",
    "\n",
    "Of course if you add new parameters and/or data specs you will need to add or modify the pipelines that use/generate them. Adding a new method is straightforward, simply define it in your extended class. Likewise overriding a method you just need to name your pipeline constructor method as it is in the base class. However, in most cases you will just want to modify the pipeline instead, in which case we use the built-in `super`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces import fsl\n",
    "fsl.BET.help()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arcana import OutputFilesetSpec\n",
    "from banana.file_format import nifti_gz_format\n",
    "\n",
    "\n",
    "class MyExtendedBasicBrainAnalysis(BasicBrainAnalysis, metaclass=AnalysisMetaClass):\n",
    "    \n",
    "    add_data_specs = [\n",
    "        OutputFilesetSpec('skull_mask', nifti_gz_format,\n",
    "                          'brain_extraction_pipeline',\n",
    "                          desc=\"Skull mask extracted from magnitude image\"),\n",
    "    ]\n",
    "    \n",
    "    def brain_extraction_pipeline(self, **name_maps):\n",
    "        pipeline = super().brain_extraction_pipeline(**name_maps)\n",
    "        \n",
    "        bet = pipeline.node('bet')\n",
    "\n",
    "        # Set the input of the BET node so that it outputs a Skull mask\n",
    "        bet.inputs.surfaces = True\n",
    "        \n",
    "        pipeline.connect_output('skull_mask', bet, 'skull_mask_file', nifti_gz_format)\n",
    "        \n",
    "        return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Default Initialisations and Output Methods\n",
    "\n",
    "If your extension is specific to a particular study, it can make things more convenient to add a 'default' classmethod that instantiates the Analysis class with links to where the study data is stored.\n",
    "\n",
    "Likewise, you can add methods for specific publication outputs (e.g. figures) to your class. This makes it easy to try to replicate your results on other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "from nilearn import plotting, image\n",
    "from arcana import Dataset, FilesetFilter, SingleProc\n",
    "from arcana import OutputFilesetSpec\n",
    "from banana.file_format import nifti_gz_format\n",
    "\n",
    "\n",
    "class MyExtendedBasicBrainAnalysis(BasicBrainAnalysis, metaclass=AnalysisMetaClass):\n",
    "    \n",
    "    add_data_specs = [\n",
    "        OutputFilesetSpec('skull_mask', nifti_gz_format,\n",
    "                          'brain_extraction_pipeline',\n",
    "                          desc=\"Skull mask extracted from magnitude image\"),\n",
    "    ]\n",
    "    \n",
    "    def brain_extraction_pipeline(self, **name_maps):\n",
    "        pipeline = super().brain_extraction_pipeline(**name_maps)\n",
    "        \n",
    "        bet = pipeline.node('bet')\n",
    "\n",
    "        # Set the input of the BET node so that it outputs a Skull mask\n",
    "        bet.inputs.surfaces = True\n",
    "        \n",
    "        pipeline.connect_output('skull_mask', bet, 'skull_mask_file', nifti_gz_format)\n",
    "        \n",
    "        return pipeline\n",
    "\n",
    "    @classmethod\n",
    "    def default(cls, name='my_analysis'):\n",
    "         return cls(\n",
    "            name,\n",
    "            dataset=Dataset('output/sample-datasets/depth1', depth=1),\n",
    "            processor=SingleProc('work'),\n",
    "            inputs=[\n",
    "                FilesetFilter('magnitude', '.*T1w$', is_regex=True)])\n",
    "\n",
    "    def plot_slices(self, spec_name, title, subject_id='sub1', visit_id='VISIT'):\n",
    "        plotting.plot_anat(\n",
    "            image.load_img(self.data(spec_name).item(\n",
    "                subject_id=subject_id, visit_id=visit_id).path),\n",
    "            title=title, display_mode='z', dim=-1,\n",
    "            cut_coords=[-20, -10, 0, 10, 20, 30])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then easily initalise the analysis, derive the data and plot the results by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = MyExtendedBasicBrainAnalysis.default()\n",
    "analysis.derive('skull_mask')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis.plot_slices('skull_mask', 'Skull Mask')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Modify the `smooth_mask_pipeline` so that it uses the 'sigma' parameter instead of the 'fwhm' parameter to define the smoothing kernel and then plot the results of `smooth_masked`. Note you to unset the 'fwhm' parameter you will need to use 'Undefined from `from traits.trait_base import Undefined`.\n",
    "\n",
    "Try extending from the extended class above (i.e. doubly extended) to reimplement `smooth_mask_pipeline`.\n",
    "\n",
    "NB: As you are changing the parameters used from the previously run analysis, you will need to either specify a new name for your analysis (e.g. 'my_second_analysis') or set the `reprocess` of the processor to `True` (e.g. `analysis.processor.reprocess = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "outputs": [],
   "source": [
    "## Write your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from traits.trait_base import Undefined\n",
    "\n",
    "\n",
    "class MyExtendedExtendedBasicBrainAnalysis(MyExtendedBasicBrainAnalysis, metaclass=AnalysisMetaClass):\n",
    "    \n",
    "    def smooth_mask_pipeline(self, **name_maps):\n",
    "        pipeline = super().smooth_mask_pipeline(**name_maps)\n",
    "        \n",
    "        smooth = pipeline.node('smooth')\n",
    "\n",
    "        # Set the input of the BET node so that it outputs a Skull mask\n",
    "        smooth.inputs.fwhm = Undefined\n",
    "        smooth.inputs.sigma = 2.0\n",
    "        \n",
    "        return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "analysis = MyExtendedExtendedBasicBrainAnalysis.default('my_second_analysis')\n",
    "analysis.derive('smooth_masked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "analysis.plot_slices('smooth_masked', 'Smooth Mask')"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
