{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Pre-Implemented Analyses\n",
    "\n",
    "An *Analysis* class can be applied to a dataset in a flexible manner, such as the parameterisation how and where the data is stored, which derivatives are required, and the computing environment in which to generate the derivatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the Analysis Class\n",
    "\n",
    "We will start by importing a predefined Analysis class from `example.analysis`, which performs the same analysis as the workflow in the [Workflows Notebook](basic_workflow.ipynb). We print the \"menu\", the list of inputs, derivatives and parameters objects of this class can receive/derive, using the `static_menu` class method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "example.analysis.BasicBrainAnalysis Menu \n",
      "-----------------------------------------\n",
      "\n",
      "Inputs:\n",
      "    magnitude : nifti_gz\n",
      "        A magnitude image (e.g. T1w, T2w, etc..)\n",
      "\n",
      "Derivatives:\n",
      "    brain : nifti_gz\n",
      "        Skull-stripped magnitude image\n",
      "    brain_mask : nifti_gz\n",
      "        Brain mask used for skull-stripping\n",
      "    smooth : nifti_gz\n",
      "        Smoothed magnitude image\n",
      "    smooth_masked : nifti_gz\n",
      "        Smoothed and masked magnitude image\n",
      "\n",
      "Parameters:\n",
      "    smoothing_fwhm : float\n",
      "        The full-width-half-maxium radius of the smoothing kernel\n"
     ]
    }
   ],
   "source": [
    "from example.analysis import BasicBrainAnalysis\n",
    "print(BasicBrainAnalysis.static_menu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the dataset to analyse\n",
    "\n",
    "Arcana implicitly handles a lot of the menial tasks involved with data input/outputs such as file format conversions and inserting/retrieving data from a repository service (i.e. XNAT). In defining the dataset to analyse you first define the repository it is stored within and then map elements of the dataset to data menu entries in the Analysis class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
