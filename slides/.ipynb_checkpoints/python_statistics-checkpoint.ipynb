{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this Notebook we'll take a look at some general tools for doing statistics in python concentrating on the `pandas`, `scipy.stats` and the `pingouin` libraries.\n",
    "\n",
    "- [Pandas](http://pandas.pydata.org/pandas-docs/stable/) will be mostly used for descriptive statistics and explorative plotting\n",
    "- [Pingouin](https://pingouin-stats.org/index.html) offers great implementation of staistical basics\n",
    "- [scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html) shows great flexibility and allows for extensive modelling approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The pandas data-frame\n",
    "\n",
    "### Creating dataframes: reading data files or converting arrays\n",
    " \n",
    "#### Reading from a CSV file\n",
    "Using the above CSV file that gives observations of brain size and weight and IQ (Willerman et al. 1991), the data are a mixture of numerical and categorical values::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_brain = pd.read_csv('data/brain_size.csv', sep=';', na_values=\".\")\n",
    "data_brain.dropna(how=\"any\", inplace=True)\n",
    "data_brain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating from arrays\n",
    "A `pandas.DataFrame` can also be seen as a dictionary of 1D 'series', eg arrays or lists. If we have 3 ``numpy`` arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "t = np.linspace(-6, 6, 20)\n",
    "sin_t = np.sin(t)\n",
    "cos_t = np.cos(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can expose them as a `pandas.DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'t': t, 'sin': sin_t, 'cos': cos_t}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other inputs**: [pandas](http://pandas.pydata.org) can input data from SQL, excel files, or other formats. See the [pandas documentation](http://pandas.pydata.org)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating data\n",
    "\n",
    "`data` is a `pandas.DataFrame`, that resembles R's dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_brain.shape    # 40 rows and 8 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_brain.columns  # It has columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_brain['Hair'].head())  # Columns can be addressed by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpler selector\n",
    "data_brain[data_brain['Hair'] == 'white']['VIQ'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** For a quick view on a large dataframe, use its `describe` `pandas.DataFrame.describe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_brain.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency count for a given column\n",
    "data_brain['Height'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy-code # of hair color (i.e., get N-binary columns)\n",
    "pd.get_dummies(data_brain['Hair'])[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The [split-apply-combine](https://www.jstatsoft.org/article/view/v040i01/v40i01.pdf) pattern\n",
    "* A very common data processing strategy is to...\n",
    "    * Split the dataset into groups\n",
    "    * Apply some operation(s) to each group\n",
    "    * (Optionally) combine back into one dataset\n",
    "\n",
    "Pandas provides powerful and fast tools for this. For example the `groupby` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**groupby**: splitting a dataframe on values of categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_hair = data_brain.groupby('Hair')\n",
    "for hair, value in groupby_hair['VIQ']:\n",
    "     print((hair, value.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`groupby_hair` is a powerful object that exposes many operations on the resulting group of dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_hair.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Exercise\n",
    "\n",
    "* What is the mean value for VIQ for the full population?\n",
    "* How many black/white haired people were included in this study?\n",
    "* What is the average value of MRI counts expressed in log units, for people with black and white hair?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "data_brain['VIQ'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "groupby_hair['Hair'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "np.log(groupby_hair.MRI_Count.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting data\n",
    "\n",
    "Pandas comes with some plotting tools (`pandas.tools.plotting`, using\n",
    "matplotlib behind the scene) to display statistics of the data in\n",
    "dataframes.\n",
    "\n",
    "For example, let's use `boxplot` (in this case even `groupby_hair.boxplot`) to better understand the structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "groupby_hair.boxplot(column=['FSIQ', 'VIQ', 'PIQ']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.plotting.scatter_matrix(data_brain[['Weight', 'Height', 'FSIQ']]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://github.com/raphaelvallat/pingouin/blob/master/docs/pictures/logo_pingouin.png?raw=true\" height=\"300\" width=\"700\"/>\n",
    "\n",
    "\n",
    "\n",
    "### _Pingouin is an open-source statistical package written in Python 3 and based mostly on Pandas and NumPy._\n",
    "\n",
    "\n",
    "- ANOVAs: one- and two-ways, repeated measures, mixed, ancova\n",
    "- Post-hocs tests and pairwise comparisons\n",
    "- Robust correlations\n",
    "- Partial correlation, repeated measures correlation and intraclass correlation\n",
    "- Linear/logistic regression and mediation analysis\n",
    "- Bayesian T-test and Pearson correlation\n",
    "- Tests for sphericity, normality and homoscedasticity\n",
    "- Effect sizes and power analysis\n",
    "- Parametric/bootstrapped confidence intervals around an effect size or a correlation coefficient\n",
    "- Circular statistics\n",
    "- Plotting: Bland-Altman plot, Q-Q plot, etc...\n",
    "\n",
    "**Pingouin is designed for users who want simple yet exhaustive statistical functions.**\n",
    "\n",
    "\n",
    "##### **material scavenged from **[*10 minutes to Pingouin*](https://pingouin-stats.org/index.html) and [*the pingouin docs*](https://pingouin-stats.org/api.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pingouin as pg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Measures of correlation](https://pingouin-stats.org/generated/pingouin.corr.html#pingouin.corr)\n",
    "\n",
    "\"In the broadest sense correlation is any statistical association, though in common usage it most often refers to how close two variables are to having a linear relationship with each other\" - [Wikipedia](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient)\n",
    "\n",
    "When talking about correlation, we commonly mean the Pearson correlation coefficient, also referred to as Pearson's r\n",
    "\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/93185aed3047ef42fa0f1b6e389a4e89a5654afa\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_correlation = pg.corr(data_brain['FSIQ'], data_brain['VIQ'])\n",
    "display(pearson_correlation)\n",
    "cor_coeeficient = pearson_correlation['r']\n",
    "n =  len(data_brain) # sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test summary\n",
    "\n",
    "- 'n' : Sample size (after NaN removal)\n",
    "- 'outliers' : number of outliers (only for 'shepherd' or 'skipped')\n",
    "- 'r' : Correlation coefficient\n",
    "- 'CI95' : [95% parametric confidence intervals](https://en.wikipedia.org/wiki/Confidence_interval)\n",
    "- 'r2' : [R-squared](https://en.wikipedia.org/wiki/Coefficient_of_determination)\n",
    "- 'adj_r2' : [Adjusted R-squared](https://en.wikipedia.org/wiki/Coefficient_of_determination#Adjusted_R2)\n",
    "- 'p-val' : one or two tailed p-value\n",
    "- 'BF10' : Bayes Factor of the alternative hypothesis (Pearson only)\n",
    "- 'power' : achieved power of the test (= 1 - type II error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "# Adjust the context of the plot\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context('notebook')\n",
    "sns.set_palette('pastel') # http://seaborn.pydata.org/tutorial/color_palettes.html\n",
    "\n",
    "sns.scatterplot(data_brain['FSIQ'], data_brain['VIQ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_correlation = pg.corr(data_brain['Height'], data_brain['VIQ'])\n",
    "display(pearson_correlation)\n",
    "cor_coeeficient = pearson_correlation['r']\n",
    "n =  len(data_brain) # sample size\n",
    "\n",
    "sns.scatterplot(data_brain['Height'], data_brain['VIQ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The pearson correlation can be sensitive to outliers, but more robust correlation coefficients can adress the problem\n",
    "-> if you want to know more: [The instability of the Pearson correlation coefficient in the presence of coincidental outliers](https://www.sciencedirect.com/science/article/pii/S1544612314000865)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate some data\n",
    "np.random.seed(123)\n",
    "mean, cov, n = [4, 5], [(1, .6), (.6, 1)], 30\n",
    "x, y = np.random.multivariate_normal(mean, cov, n).T\n",
    "\n",
    "display(pg.corr(x, y))\n",
    "\n",
    "# Introduce an outlier\n",
    "x[0] = 80\n",
    "\n",
    "display(pg.corr(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the robust Shepherd's pi correlation\n",
    "display(pg.corr(x, y, method=\"shepherd\"))\n",
    "\n",
    "display(pg.corr(x, y, method=\"skipped\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Plot a robust Skipped correlation with bootstrapped confidence intervals](https://pingouin-stats.org/generated/pingouin.plot_skipped_corr.html#pingouin.plot_skipped_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "mean, cov, n = [170, 70], [[20, 10], [10, 20]], 30\n",
    "x, y = np.random.multivariate_normal(mean, cov, n).T\n",
    "# Introduce two outliers\n",
    "x[10], y[10] = 160, 100\n",
    "x[8], y[8] = 165, 90\n",
    "fig = pg.plot_skipped_corr(x, y, xlabel='Height', ylabel='Weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excercise\n",
    "display(pg.corr(data_brain['FSIQ'], data_brain['VIQ'], method=\"skipped\"))\n",
    "fig = pg.plot_skipped_corr(data_brain['FSIQ'], data_brain['VIQ'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pg.corr(data_brain['Height'], data_brain['VIQ'], method=\"skipped\"))\n",
    "fig = pg.plot_skipped_corr(data_brain['VIQ'],data_brain['Height'], ylabel='Height', xlabel='VIQ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise correlations between columns of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "z = np.random.normal(5, 1, 30)\n",
    "data_pairwise = pd.DataFrame({'X': x, 'Y': y, 'Z': z})\n",
    "\n",
    "# Pairwise correlation sorted from largest to smallest R2\n",
    "pg.pairwise_corr(data_pairwise, columns=['X', 'Y', 'Z']).sort_values(by=['r2'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we calculate:  `Testing statistical premises`\n",
    "\n",
    "Statistical procedures can be classfied into either [`parametric`](https://en.wikipedia.org/wiki/Parametric_statistics) or `non parametric` prcedures, which require different necessary preconditions to be met in order to show consistent/robust results. \n",
    "Generally people assume that their data follows a gaussian distribution, which allows for parametric tests to be run.\n",
    "Nevertheless it is essential to first test the distribution of your data to decide if the assumption of normally distributed data holds, if this is not the case we would have to switch to non parametric tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`T-tests` and the like depend on:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Shapiro Wilk normality  test](https://pingouin-stats.org/generated/pingouin.normality.html#pingouin.normality)\n",
    "\n",
    "Standard procedure to test for normal distribution. Tests if the distribution of you data deviates significtanly from a normal distribution.\n",
    "returns:\n",
    "- normal : boolean\n",
    "    True if x comes from a normal distribution.\n",
    "\n",
    "- p : float\n",
    "    P-value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a boolean (true if normal) and the associated p-value\n",
    "normal, p = pg.normality(data_brain['Height'], data_brain['VIQ'], alpha=.05)\n",
    "print(normal, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise\n",
    "How would you interpret this outcome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Henze-Zirkler multivariate normality test](https://pingouin-stats.org/generated/pingouin.multivariate_normality.html#pingouin.multivariate_normality)\n",
    "\n",
    "Same procedure for [multiivariate normal distributions](https://en.wikipedia.org/wiki/Multivariate_normal_distribution)\n",
    "\n",
    "returns \n",
    "\n",
    "- normal : boolean\n",
    "    True if X comes from a multivariate normal distribution.\n",
    "\n",
    "- p : float\n",
    "    P-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return a boolean (true if normal) and the associated p-value\n",
    "np.random.seed(123)\n",
    "mean, cov, n = [4, 6], [[1, .5], [.5, 1]], 30\n",
    "X = np.random.multivariate_normal(mean, cov, n)\n",
    "normal, p = pg.multivariate_normality(X, alpha=.05)\n",
    "print(normal, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise\n",
    "How would you interpret this outcome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Variance analysis` depend on:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Mauchly test for sphericity](https://pingouin-stats.org/generated/pingouin.sphericity.html#pingouin.sphericity)\n",
    "\n",
    "\"Sphericity is the condition where the variances of the differences between all combinations of related groups (levels) are equal. Violation of sphericity is when the variances of the differences between all combinations of related groups are not equal.\" - https://statistics.laerd.com/statistical-guides/sphericity-statistical-guide.php\n",
    "\n",
    "\n",
    "returns \n",
    "\n",
    "- spher : boolean\n",
    "    True if data have the sphericity property.\n",
    "\n",
    "- W : float\n",
    "    Test statistic\n",
    "\n",
    "- chi_sq : float\n",
    "    Chi-square statistic\n",
    "\n",
    "- ddof : int\n",
    "    Degrees of freedom\n",
    "\n",
    "- p : float\n",
    "    P-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.sphericity(data_brain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise\n",
    "How would you interpret this outcome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Testing for homoscedasticity](https://pingouin-stats.org/generated/pingouin.homoscedasticity.html#pingouin.homoscedasticity)\n",
    "\n",
    "\"In statistics, a sequence or a vector of random variables is homoscedastic /ˌhoʊmoʊskəˈdæstɪk/ if all random variables in the sequence or vector have the same finite variance.\" - [wikipedia](https://en.wikipedia.org/wiki/Homoscedasticity)\n",
    "\n",
    "returns:\t\n",
    "- equal_var : boolean\n",
    "    True if data have equal variance.\n",
    "\n",
    "- p : float\n",
    "    P-value.\n",
    "\n",
    "\n",
    "*Note:\n",
    "This function first tests if the data are normally distributed using the **Shapiro-Wilk test**. If yes, then the homogeneity of variances is measured using the **Bartlett test**. If the data are not normally distributed, the **Levene test**, which is less sensitive to departure from normality, is used.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "# Scale = standard deviation of the distribution.\n",
    "array_1 = np.random.normal(loc=0, scale=1., size=100)\n",
    "array_2 = np.random.normal(loc=0, scale=0.8,size=100)\n",
    "print(np.var(array_1), np.var(array_2))\n",
    "\n",
    "equal_var, p = pg.homoscedasticity(array_1, array_2, alpha=.05)\n",
    "print(equal_var, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise\n",
    "How would you interpret this outcome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric tests\n",
    "## Student's t-test: the simplest statistical test\n",
    "\n",
    "### 1-sample t-test: testing the value of a population mean\n",
    "\n",
    "tests if the population mean of data is likely to be equal to a given value (technically if observations are drawn from a Gaussian distributions of given population mean).\n",
    "\n",
    "`scipy.stats.ttest_1samp` returns the [T statistic](https://en.wikipedia.org/wiki/Student%27s_t-test), and the [p-value](https://en.wikipedia.org/wiki/P-value) (see the function's help): \n",
    "\n",
    "`pingouin.ttest` returns the T_statistic, the p-value, the [degrees of freedom](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics), the [Cohen d effect size](https://en.wikiversity.org/wiki/Cohen%27s_d), the achieved [power](https://en.wikipedia.org/wiki/Power_(statistics%29) of the test ( = 1 - type II error (beta) = [P(Reject H0|H1 is true)](https://deliveroo.engineering/2018/12/07/monte-carlo-power-analysis.html)), and the [Bayes Factor](https://en.wikipedia.org/wiki/Bayes_factor) of the alternative hypothesis\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy\n",
    "from scipy import stats\n",
    "print('Scipy:')\n",
    "display(stats.ttest_1samp(data_brain['VIQ'], 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "and with [`pingouin.ttest`](https://pingouin-stats.org/generated/pingouin.ttest.html#pingouin.ttest)\n",
    "\n",
    "\n",
    "\n",
    "**Parameters:**\t\n",
    "- x : array_like\n",
    "    First set of observations.\n",
    "\n",
    "- y : array_like or float\n",
    "    Second set of observations. If y is a single value, a one-sample T-test is computed.\n",
    "\n",
    "- paired : boolean\n",
    "    Specify whether the two observations are related (i.e. repeated measures) or independent.\n",
    "\n",
    "- tail : string\n",
    "    Specify whether to return two-sided or one-sided p-value.\n",
    "\n",
    "- correction : string or boolean\n",
    "    For unpaired two sample T-tests, specify whether or not to correct for unequal variances using Welch separate variances T-test. If ‘auto’, it will automatically uses Welch T-test when the sample sizes are unequal, as recommended by Zimmerman 2004.\n",
    "\n",
    "- `r` : `prior`\n",
    "    Cauchy scale factor for computing the Bayes Factor. Smaller values of r (e.g. 0.5), may be appropriate when small effect sizes are expected a priori; larger values of r are appropriate when large effect sizes are expected (Rouder et al 2009). The default is 0.707 (= sqrt(2) / 2).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pingouin\n",
    "\n",
    "print('Pingouin:')\n",
    "pg.ttest(data_brain['VIQ'],0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a p-value of 10^-28 we can claim that the population mean for the IQ (VIQ measure) is not 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-sample t-test: testing for difference across populations\n",
    "\n",
    "We have seen above that the mean VIQ in the black hair and white hair populations\n",
    "were different. To test if this is significant, we do a 2-sample t-test\n",
    "with `scipy.stats.ttest_ind`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_viq = data_brain[data_brain['Hair'] == 'white']['VIQ']\n",
    "black_viq = data_brain[data_brain['Hair'] == 'black']['VIQ']\n",
    "\n",
    "# scipy\n",
    "stats.ttest_ind(white_viq, black_viq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pingouin\n",
    "pg.ttest(white_viq, black_viq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot achieved power of a paired T-test\n",
    "\n",
    "Plot the curve of achieved power given the effect size (Cohen d) and the sample size of a paired T-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='ticks', context='notebook', font_scale=1.2)\n",
    "\n",
    "d = 0.5  # Fixed effect size\n",
    "n = np.arange(5, 80, 5)  # Incrementing sample size\n",
    "\n",
    "# Compute the achieved power\n",
    "pwr = pg.power_ttest(d=d, n=n, contrast='paired', tail='two-sided')\n",
    "\n",
    "# Start the plot\n",
    "plt.plot(n, pwr, 'ko-.')\n",
    "plt.axhline(0.8, color='r', ls=':')\n",
    "plt.xlabel('Sample size')\n",
    "plt.ylabel('Power (1 - type II error)')\n",
    "plt.title('Achieved power of a paired T-test')\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non parametric tests:\n",
    "\n",
    "\n",
    "Unlike the parametric test these do not require the assumption of normal distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"`Mann-Whitney U Test` (= Wilcoxon rank-sum test). It is the non-parametric version of the independent T-test.\n",
    "Mwu tests the hypothesis that data in x and y are samples from continuous distributions with equal medians. The test assumes that x and y are independent. This test corrects for ties and by default uses a continuity correction.\" - [mwu-function](https://pingouin-stats.org/generated/pingouin.mwu.html#pingouin.mwu)\n",
    "\n",
    "Test summary\n",
    "\n",
    "- 'W-val' : W-value\n",
    "- 'p-val' : p-value\n",
    "- 'RBC'   : matched pairs rank-biserial correlation (effect size)\n",
    "- 'CLES'  : common language effect size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the medians of two independent samples.\n",
    "pg.mwu(white_viq, black_viq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise\n",
    "How would you interpret this outcome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"`Wilcoxon signed-rank test` is the non-parametric version of the paired T-test.\n",
    "\n",
    "The Wilcoxon signed-rank test tests the null hypothesis that two related paired samples come from the same distribution. A continuity correction is applied by default.\" - [wilcoxon - func](https://pingouin-stats.org/generated/pingouin.wilcoxon.html#pingouin.wilcoxon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example from the function definition\n",
    "# Wilcoxon test on two related samples.\n",
    "x = [20, 22, 19, 20, 22, 18, 24, 20]\n",
    "y = [38, 37, 33, 29, 14, 12, 20, 22]\n",
    "print(\"Medians = %.2f - %.2f\" % (np.median(x), np.median(y)))\n",
    "pg.wilcoxon(x, y, tail='two-sided')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise\n",
    "How would you interpret this outcome?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `statsmodels` - use \"formulas\" to specify statistical models in Python\n",
    "\n",
    "Use `statsmodels` to perform linear models, multiple factors or analysis of variance.\n",
    "\n",
    "\n",
    "## A simple linear regression\n",
    "\n",
    "Given two set of observations, `x` and `y`, we want to test the hypothesis that `y` is a linear function of `x`.\n",
    "\n",
    "In other terms:\n",
    "\n",
    "$y = x * coef + intercept + e$\n",
    "\n",
    "where $e$ is observation noise. We will use the [statsmodels](http://statsmodels.sourceforge.net) module to:\n",
    "\n",
    "1. Fit a linear model. We will use the simplest strategy, [ordinary least squares](https://en.wikipedia.org/wiki/Ordinary_least_squares) (OLS).\n",
    "2. Test that $coef$ is non zero.\n",
    "\n",
    "First, we generate simulated data according to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(-5, 5, 20)\n",
    "np.random.seed(1)\n",
    "\n",
    "# normal distributed noise\n",
    "y = -5 + 3*x + 4 * np.random.normal(size=x.shape)\n",
    "\n",
    "# Create a data frame containing all the relevant variables\n",
    "data_regr = pd.DataFrame({'x': x, 'y': y})\n",
    "\n",
    "plt.plot(x, y, 'o');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we specify an OLS model and fit it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "model = ols(\"y ~ x\", data_regr).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** For more about \"formulas\" for statistics in Python, see the [statsmodels documentation](http://statsmodels.sourceforge.net/stable/example_formulas.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the various statistics derived from the fit::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Terminology\n",
    "\n",
    "Statsmodels uses a statistical terminology: the `y` variable in statsmodels is called *endogenous* while the `x` variable is called *exogenous*. This is discussed in more detail [here](http://statsmodels.sourceforge.net/devel/endog_exog.html). To simplify, `y` (endogenous) is the value you are trying to predict, while `x` (exogenous) represents the features you are using to make the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Retrieve the estimated parameters from the model above.  \n",
    "**Hint**: use tab-completion to find the relevant attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write a comparison between IQ of people with black and white hair using a linear model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols(\"VIQ ~ Hair + 1\", data_brain).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips on specifying model\n",
    " \n",
    "***Forcing categorical*** - the 'Hair' is automatically detected as a categorical variable, and thus each of its different values are treated as different entities.\n",
    "\n",
    "An integer column can be forced to be treated as categorical using:\n",
    "\n",
    "```python\n",
    "model = ols('VIQ ~ C(Hair)', data).fit()\n",
    "```\n",
    "\n",
    "***Intercept***: We can remove the intercept using `- 1` in the formula, or force the use of an intercept using `+ 1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Link to t-tests between different FSIQ and PIQ\n",
    "\n",
    "To compare different types of IQ, we need to create a \"long-form\" table, listing IQs, where the type of IQ is indicated by a categorical variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fisq = pd.DataFrame({'iq': data_brain['FSIQ'], 'type': 'fsiq'})\n",
    "data_piq = pd.DataFrame({'iq': data_brain['PIQ'], 'type': 'piq'})\n",
    "data_long = pd.concat((data_fisq, data_piq))\n",
    "print(data_long[::8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ols(\"iq ~ type\", data_long).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise\n",
    "* use pingouin to test for differences in `FSIQ` and `PIQ`\n",
    "\n",
    "* Can we see that we retrieve the same values for t-test and\n",
    "    corresponding p-values for the effect of the type of iq than the\n",
    "    previous t-test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution\n",
    "#pg.ttest(data_brain['FSIQ'], data_brain['PIQ'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Regression: including multiple factors\n",
    "\n",
    "Consider a linear model explaining a variable `z` (the dependent\n",
    "variable) with 2 variables `x` and `y`:\n",
    "\n",
    "$z = x \\, c_1 + y \\, c_2 + i + e$\n",
    "\n",
    "Such a model can be seen in 3D as fitting a plane to a cloud of (`x`,\n",
    "`y`, `z`) points (see the following figure)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "x = np.linspace(-5, 5, 21)\n",
    "\n",
    "# We generate a 2D grid\n",
    "X, Y = np.meshgrid(x, x)\n",
    "\n",
    "# To get reproducable values, provide a seed value\n",
    "np.random.seed(1)\n",
    "\n",
    "# Z is the elevation of this 2D grid\n",
    "Z = -5 + 3*X - 0.5*Y + 8 * np.random.normal(size=X.shape)\n",
    "\n",
    "# Plot the data\n",
    "fig = plt.figure()\n",
    "ax = fig.gca(projection='3d')\n",
    "surf = ax.plot_surface(X, Y, Z, cmap=plt.cm.coolwarm,\n",
    "                       rstride=1, cstride=1)\n",
    "ax.view_init(20, -120)\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: the iris data (`data/iris.csv`)\n",
    "\n",
    "Sepal and petal size tend to be related: bigger flowers are bigger! But is there in addition a systematic effect of species?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "#Load the data\n",
    "data_iris = pd.read_csv('data/iris.csv')\n",
    "\n",
    "# Express the names as categories\n",
    "categories = pd.Categorical(data_iris['Species'])\n",
    "\n",
    "# The parameter 'c' is passed to plt.scatter and will control the color\n",
    "scatter_matrix(data_iris, c=categories.codes, marker='o')\n",
    "\n",
    "# Plot figure\n",
    "fig.suptitle(\"blue: setosa, green: versicolor, red: virginica\", size=13)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iris = pd.read_csv('data/iris.csv')\n",
    "model = ols('SepalWidth ~ Species + PetalLength', data_iris).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Multiple) [linear regression in pingouin](https://pingouin-stats.org/generated/pingouin.linear_regression.html#pingouin.linear_regression)\n",
    "\n",
    "More streamlined, simple approach\n",
    "- beta coefficients of the regression are estimated using the numpy.linalg.lstsq() function\n",
    "\n",
    "**Parameters:**\t\n",
    "- X : np.array or list\n",
    "    Predictor(s). Shape = (n_samples, n_features) or (n_samples,).\n",
    "\n",
    "- y : np.array or list\n",
    "    Dependent variable. Shape = (n_samples).\n",
    "\n",
    "- add_intercept : bool\n",
    "    If False, assume that the data are already centered. If True, add a constant term to the model. In this case,       the first value in the output dict is the intercept of the model.\n",
    "\n",
    "- coef_only : bool\n",
    "    If True, return only the regression coefficients.\n",
    "\n",
    "- alpha : float\n",
    "    Alpha value used for the confidence intervals. CI = [alpha / 2 ; 1 - alpha / 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses the numpy internal function\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.lstsq.html#numpy.linalg.lstsq\n",
    "lm = pg.linear_regression(data_brain['FSIQ'], data_brain['VIQ'])\n",
    "display(lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.linear_regression(data_brain[['FSIQ', 'VIQ']], data_brain['Height']).round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-hoc hypothesis testing: analysis of variance (ANOVA)\n",
    "\n",
    "In the above iris example, we wish to test if the petal length is different between versicolor and virginica, after removing the effect of sepal width. This can be formulated as testing the difference between the coefficient associated to versicolor and virginica in the linear model estimated above (it is an Analysis of Variance, [ANOVA](https://en.wikipedia.org/wiki/Analysis_of_variance). For this, we write a **vector of 'contrast'** on the parameters estimated: we want to test ``\"name[T.versicolor] - name[T.virginica]\"``, with an [F-test](https://en.wikipedia.org/wiki/F-test):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.f_test([0, 1, -1, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this difference significant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Going back to the brain size + IQ data, test if the VIQ of people with black and white hair are different after removing the effect of brain size, height and weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "#data = pd.read_csv('data/brain_size.csv', sep=';', na_values=\".\")\n",
    "model = ols(\"VIQ ~ Hair + Height + Weight + MRI_Count\", data_brain).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-way ANOVA using a pandas DataFrame in Pingouin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read an example dataset\n",
    "from pingouin.datasets import read_dataset\n",
    "df = read_dataset('mixed_anova')\n",
    "\n",
    "# Run the ANOVA\n",
    "aov = pg.anova(data=df, dv='Scores', between='Group', detailed=True)\n",
    "aov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeated measures ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.rm_anova(data=df, dv='Scores', within='Time', subject='Subject', detailed=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-hoc tests corrected for multiple-comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FDR-corrected post hocs with Hedges'g effect size\n",
    "posthoc = pg.pairwise_ttests(data=df, dv='Scores', within='Time', subject='Subject', \n",
    "                             padjust='fdr_bh', effsize='hedges')\n",
    "\n",
    "# Pretty printing of table\n",
    "pg.print_table(posthoc, floatfmt='.3f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non-parametric version (= pairwise wilcoxon tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FDR-corrected post hocs with Hedges'g effect size\n",
    "pg.pairwise_ttests(data=df, dv='Scores', within='Time', subject='Subject', \n",
    "                   padjust='fdr_bh', effsize='hedges').round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-way mixed ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aov = pg.mixed_anova(data=df, dv='Scores', between='Group', within='Time',\n",
    "                       subject='Subject', correction=False,\n",
    "                       export_filename='mixed_anova.csv')\n",
    "pg.print_table(aov)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `seaborn` - use visualization for statistical exploration\n",
    "\n",
    "[Seaborn](http://stanford.edu/~mwaskom/software/seaborn/) combines simple statistical fits with plotting on pandas dataframes.\n",
    "\n",
    "Let us consider a data giving wages and many other personal information on 500 individuals ([Berndt, ER. The Practice of Econometrics. 1991. NY:Addison-Wesley](http://lib.stat.cmu.edu/datasets/CPS_85_Wages))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_wages = pd.read_csv('data/wages.csv', sep=',')\n",
    "data_wages.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairplot: scatter matrices\n",
    "\n",
    "We can easily have an intuition on the interactions between continuous variables using `seaborn.pairplot` to display a scatter matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "seaborn.set()\n",
    "seaborn.pairplot(data_wages, vars=['WAGE', 'AGE', 'EDUCATION'], kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorical variables can be plotted as the hue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.pairplot(data_wages, vars=['WAGE', 'AGE', 'EDUCATION'], kind='reg', hue='HAIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lmplot: plotting a univariate regression\n",
    "\n",
    "A regression capturing the relation between one variable and another, e.g. wage and eduction, can be plotted using `seaborn.lmplot`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.lmplot(y='WAGE', x='EDUCATION', data=data_wages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Robust regression\n",
    "Given that, in the above plot, there seems to be a couple of data points that are outside of the main cloud to the right, they might be outliers, not representative of the population, but driving the regression.\n",
    "\n",
    "To compute a regression that is less sensitive to outliers, one must use a [robust model](https://en.wikipedia.org/wiki/Robust_statistics). This is done in seaborn using ``robust=True`` in the plotting functions, or in statsmodels by replacing the use of the OLS by a \"Robust Linear Model\", `statsmodels.formula.api.rlm`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for interactions\n",
    "\n",
    "Do wages increase more with education for people with black hair than with white hair?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.lmplot(y='WAGE', x='EDUCATION', hue='HAIR', data=data_wages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above is made of two different fits. We need to formulate a single model that tests for a variance of slope across the to population. This is done via an [\"interaction\"](http://statsmodels.sourceforge.net/devel/example_formulas.html#multiplicative-interactions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "result = ols(formula='WAGE ~ EDUCATION + HAIR + EDUCATION * HAIR', data=data_wages).fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we conclude that education benefits people with black hair more than people with white hair?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Take home messages\n",
    "\n",
    "* test your premises!\n",
    "\n",
    "* Hypothesis testing and p-value give you the **significance** of an effect / difference\n",
    "\n",
    "* **Formulas** (with categorical variables) enable you to express rich links in your data\n",
    "\n",
    "* **Visualizing** your data and simple model fits matters!\n",
    "\n",
    "* **Conditioning** (adding factors that can explain all or part of the variation) is important modeling aspect that changes the interpretation.\n",
    "\n",
    "\n",
    "* `scipy.stats` = great for regressions and model building (and if you want to get real crazy)\n",
    "* `pingouin` = better for \"simpler\" statistics\n",
    "    - but pingouin is relatively new -> extension and further development in the future\n",
    "      <img src=\"https://pingouin-stats.org/_static/pingouin_128x128.png\" height=\"20\" width=\"20\"/>\n",
    "\n",
    " \n",
    "* great resource for learning statistics basics -> http://greenteapress.com/wp/think-stats-2e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
